{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensor_tutorial.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"-0TK2HvBtCXp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# First: Install PyTorch and torchvision\n","!pip3 install torch torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PIuEiTJpzSZC","colab_type":"text"},"cell_type":"markdown","source":["# What is PyTorch?\n","\n","It’s a Python based scientific computing package targeted at two sets of\n","audiences:\n","-  A replacement for NumPy to use the power of GPUs\n","-  a deep learning research platform that provides maximum flexibility\n","   and speed\n","\n","## Getting Started\n","\n","### Tensors\n","\n","Tensors are similar to NumPy’s ndarrays, with the addition being that\n","Tensors can also be used on a GPU to accelerate computing."]},{"metadata":{"id":"iEW7SkqcuivT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from __future__ import print_function\n","import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ldSkq2qmz5kx","colab_type":"text"},"cell_type":"markdown","source":["Construct a 5x3 matrix, uninitialized:"]},{"metadata":{"id":"xUvCfSG0z6Za","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x = torch.empty(5, 3)\n","print(x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eg32wRh2z_Kg","colab_type":"text"},"cell_type":"markdown","source":["Construct a randomly initialized matrix:"]},{"metadata":{"id":"I_vzhrblz8wm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x = torch.rand(5, 3)\n","print(x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wtSN6OfX0GZE","colab_type":"text"},"cell_type":"markdown","source":["  Construct a matrix filled zeros and of dtype `int64`:"]},{"metadata":{"id":"4-QlwAkf0B7J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x = torch.zeros(5, 3, dtype=torch.int64)\n","print(x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fgZMFkVa0GHw","colab_type":"text"},"cell_type":"markdown","source":["Construct a tensor directly from data:"]},{"metadata":{"id":"MJvNb2lR0Qi1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x = torch.tensor([5.5, 3])\n","print(x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dfK5nte50R3c","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"TIBFW9pa0UF0","colab_type":"text"},"cell_type":"markdown","source":["or create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user"]},{"metadata":{"id":"0LkwcTUs0ZIj","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n","print(x)\n","\n","x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n","print(x)                                      # result has the same size\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9r9EKpUD0fWp","colab_type":"text"},"cell_type":"markdown","source":["Get its size:"]},{"metadata":{"id":"acdRMK7g0cLL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["print(x.size())\n","print(x.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pKnafQWZ0vc1","colab_type":"text"},"cell_type":"markdown","source":["#### note\n","     torch.Size is in fact a tuple, so it supports all tuple operations.\n","\n","### Operations\n","\n","There are multiple syntaxes for operations. In the following\n","example, we will take a look at the addition operation.\n","\n","Addition: syntax 1"]},{"metadata":{"id":"PWiVkDzz0fvQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["y = torch.rand(5, 3)\n","print(x + y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZG5WHi2e1Pt7","colab_type":"text"},"cell_type":"markdown","source":["Addition: syntax 2"]},{"metadata":{"id":"YxNqNJTs1I2y","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["print(torch.add(x, y))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZyaL9kwO1eTK","colab_type":"text"},"cell_type":"markdown","source":["Addition: providing an output tensor as argument"]},{"metadata":{"id":"NJAukKm-1gST","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["result = torch.empty(5, 3)\n","torch.add(x, y, out=result)\n","print(result)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OcixlkFY1mSK","colab_type":"text"},"cell_type":"markdown","source":["Addition: in-place"]},{"metadata":{"id":"b0ATzKnP1osR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# adds x to y\n","y.add_(x)\n","print(y)\n","\n","# or\n","y += x\n","print(y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lXZbk73m1mqv","colab_type":"text"},"cell_type":"markdown","source":["#### note\n","    Any operation that mutates a tensor in-place is post-fixed with an _.\n","    For example: x.copy_(y), x.t_(), will change x.\n","\n","You can use standard NumPy-like indexing with all bells and whistles!"]},{"metadata":{"id":"IK1MI7yu1p1T","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["print(x[:, 1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bH-85hbn1mx8","colab_type":"text"},"cell_type":"markdown","source":["Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:"]},{"metadata":{"id":"osFNs8dm1qYY","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n","print(x.size(), y.size(), z.size())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"88GoIW_Z1m6y","colab_type":"text"},"cell_type":"markdown","source":["If you have a one element tensor, use ``.item()`` to get the value as a Python number"]},{"metadata":{"id":"tOx3JDK21q7k","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["x = torch.randn(1)\n","print(x)\n","print(x.item())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5N2cNKBY1nAm","colab_type":"text"},"cell_type":"markdown","source":["**Read later:**\n","\n","\n","100+ Tensor operations, including transposing, indexing, slicing,\n","mathematical operations, linear algebra, random numbers, etc.,\n","are described\n","[here](http://pytorch.org/docs/torch).\n","\n","## NumPy Bridge\n","\n","Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n","\n","The Torch `Tensor` and NumPy `array` will share their underlying memory\n","locations, and changing one will change the other.\n","\n","### Converting a Torch Tensor to a NumPy Array"]},{"metadata":{"id":"sN5zoFkS1rT1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["a = torch.ones(5)\n","print(a)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Sx-qD8zV4Okq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["b = a.numpy()\n","print(b)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HY_4kJjP1nGS","colab_type":"text"},"cell_type":"markdown","source":["See how the numpy array changed in value."]},{"metadata":{"id":"avoIX_pV1rjs","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["a += 1\n","print(a)\n","print(b)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ko_pjkCr1nKO","colab_type":"text"},"cell_type":"markdown","source":["### Converting NumPy Array to Torch Tensor\n","\n","See how changing the np array changed the Torch Tensor automatically"]},{"metadata":{"id":"2uv4BMX41r2b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","np.add(a, 1, out=a)\n","print(a)\n","print(b)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TJseasKM1nMm","colab_type":"text"},"cell_type":"markdown","source":["All the Tensors on the CPU except a CharTensor support converting to\n","NumPy and back.\n","\n","## CUDA Tensors\n","\n","Tensors can be moved onto any device using the ``.to`` method."]},{"metadata":{"id":"aHFzRRwJ1sX5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# let us run this cell only if CUDA is available\n","# We will use ``torch.device`` objects to move tensors in and out of GPU\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    z = x + y\n","    print(z)\n","    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"],"execution_count":0,"outputs":[]}]}